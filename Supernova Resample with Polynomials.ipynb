{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import our python modules\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.utils as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.plots as plots\n",
    "from astropy.table import Table, Column\n",
    "from scipy import optimize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the database and query\n",
    "runName = 'minion_1016'\n",
    "opsdb = db.OpsimDatabase(runName + '_sqlite.db')\n",
    "\n",
    "# Set the output directory\n",
    "outDir = 'Observations Dictionary'\n",
    "resultsDb = db.ResultsDb(outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set desired filters, range of location and mangitudes of peak, and sample light curve here\n",
    "filterNames = ['g', 'r', 'i', 'z']\n",
    "colors = {'u':'cyan','g':'g','r':'blue','i':'r','z':'m', 'y':'k'}\n",
    "#Consider red filter for the two below\n",
    "location_of_peak = np.arange(0,50, 10)\n",
    "height_of_peak = np.arange(16, 18, 0.5)\n",
    "#location_of_peak = [10]\n",
    "#height_of_peak = [17]\n",
    "jsonLC = 'iPTF13bvn.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying database with no constraint.\n",
      "Found 2447931 visits\n",
      "Running:  [0]\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "# The pass metric just passes data straight through.\n",
    "#choose database and restrictions (such as list of ra and dec)\n",
    "metric = metrics.PassMetric(cols=['expMJD','filter','fiveSigmaDepth'])\n",
    "slicer = slicers.UserPointsSlicer(np.random.uniform(0,360,5), np.random.uniform(-60,-30,5))\n",
    "#no restrictions currently\n",
    "sql = ''\n",
    "bundle = metricBundles.MetricBundle(metric,slicer,sql)\n",
    "bg =  metricBundles.MetricBundleGroup({0:bundle}, opsdb,\n",
    "                                        outDir=outDir, resultsDb=resultsDb)\n",
    "bg.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createdict_for_mjd_filter_depth(bundle):\n",
    "    \n",
    "    \"\"\"This function returns a list of tables of exposure day, filter, and five sigma depth for each ra and dec chosen\"\"\"\n",
    "    \n",
    "    listofDict = []\n",
    "    for coord in range(len(bundle.metricValues)):\n",
    "        bdict = {key: bundle.metricValues[coord][key] for key in ['fieldRA', 'fieldDec', 'expMJD', 'filter', 'fiveSigmaDepth']}\n",
    "        t = Table(bdict)\n",
    "        t.rename_column('expMJD', 'day')\n",
    "        listofDict.append(t)\n",
    "    return listofDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReadCurve():\n",
    "    #Read in asciifile and interpolate data for each filter\n",
    "    \n",
    "    def __init__(self, jsonfile):\n",
    "        self.read_lightcurve(jsonfile)\n",
    "\n",
    "    def read_lightcurve(self, jsonfile):\n",
    "        # Open and load json file with sne values\n",
    "        sne_data = open(jsonfile)\n",
    "        sne = json.load(sne_data)\n",
    "        # Set up dictionary for json data\n",
    "        data = {'day': [], 'filter': [], 'mag': [], 'magerror': [], 'upperlimit': []}\n",
    "        # Use for loop to call to values within the json file\n",
    "        for entry in sne['iPTF13bvn']['photometry']:\n",
    "            # Ignore instances in which 'band' and 'magnitude' have no data\n",
    "            if 'band' in entry and 'magnitude' in entry:\n",
    "                data['day'].append(float(entry['time']))\n",
    "                data['filter'].append(entry['band'])\n",
    "                data['mag'].append(float(entry['magnitude']))\n",
    "                # Ignore instances in which 'upperlimit' has no value (i.e. is 'false')\n",
    "                if 'upperlimit' in entry:\n",
    "                    data['upperlimit'].append(entry['upperlimit'])\n",
    "                else:\n",
    "                    data['upperlimit'].append(False)\n",
    "                # Ignore instances in which 'e_magnitude' has no value (i.e. upperlimit IS the error)\n",
    "                if 'e_magnitude' in entry:\n",
    "                    data['magerror'].append(float(entry['e_magnitude']))\n",
    "                else:\n",
    "                    data['magerror'].append(99)\n",
    "        # Table the now-full dictionary of sne data\n",
    "        sne_table = Table(data)\n",
    "        # Update the table to modify the data for magnitude errors no more than 0.3, no upperlimit values,\n",
    "        # mjd in terms of obvservation day number, and filters in only g, r, i, and z.\n",
    "        sne_table = sne_table[sne_table['magerror'] < 0.3]\n",
    "        sne_table = sne_table[sne_table['upperlimit'] == False]\n",
    "        sne_table = sne_table[sne_table['filter'] != 'V']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'R']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'W1']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'B']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'U']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'I']\n",
    "        sne_table = sne_table[sne_table['filter'] != 'W2']\n",
    "        sne_table['day'] = sne_table['day'] - sne_table['day'].min()\n",
    "        sne_table = sne_table['day', 'filter', 'mag', 'magerror']\n",
    "        return sne_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_light_curve(adjusted_lc_table, survey):\n",
    "    \n",
    "    #for each filter interpolate the read in light curve to the days of the survey in all filters\n",
    "    \n",
    "    lc = {}\n",
    "    for f in filterNames:\n",
    "        fMatch = np.where(adjusted_lc_table['filter'] == f)\n",
    "        lc[f] = np.interp(survey['day'], adjusted_lc_table['day'][fMatch], adjusted_lc_table['mag'][fMatch])\n",
    "    lightcurve = Table(lc)\n",
    "    lightcurve['day'] = survey['day']\n",
    "    lightcurve = lightcurve['day', 'g', 'r', 'i', 'z']\n",
    "    return lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample_light_curve(lightcurve, opsim):\n",
    "    \n",
    "    \"\"\"add to the opsim table a magnitude column where the magnitude is taken from the index of the interpolated\n",
    "        light curve where both the filter and day matched the opsim\"\"\"\n",
    "    opsim1 = opsim.copy()\n",
    "    opsim1['magnitude'] = 0.\n",
    "    for row in range(len(opsim1)):\n",
    "        filterName = opsim1['filter'][row]\n",
    "        opsim1['magnitude'][row] = lightcurve[filterName][row]\n",
    "    opsim1 = opsim1['day','filter','magnitude','fiveSigmaDepth']\n",
    "    opsim1.sort('day')\n",
    "    return opsim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peak_brightness(lc_table):\n",
    "    \n",
    "    #This function returns a table of peak magnitude and the day it occurs for each filter from the read in lightcurve\n",
    "    \n",
    "    peak_brightness = {}\n",
    "    for f in filterNames:\n",
    "        fMatch = np.where(lc_table['filter'] == f)\n",
    "        maxmag = np.amin(lc_table['mag'][fMatch])\n",
    "        location = np.argmin(lc_table['mag'][fMatch])\n",
    "        maxday = lc_table['day'][fMatch][location]\n",
    "        peak_brightness[f] = [maxday, maxmag]\n",
    "    \n",
    "    peak = Table(peak_brightness)\n",
    "    peak[' '] = ['day', 'magnitude']\n",
    "    orderedPeak = peak[' ','g','r','i','z']\n",
    "    return orderedPeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_peak(lc_table, peaktable, peakday, peakmag):\n",
    "    \n",
    "    \"\"\"This function finds the necessary adjustment needed to make the peak of the red filter occur at the right place\n",
    "        and adjusts all filters by that same ammount\"\"\"\n",
    "    adjusted_lc_table = lc_table.copy()\n",
    "    \n",
    "    peak_day_difference = peaktable['r'][0] - peakday\n",
    "    adjusted_lc_table['day'] = adjusted_lc_table['day'] - peak_day_difference\n",
    "    \n",
    "    peak_mag_difference = peaktable['r'][1] - peakmag\n",
    "    adjusted_lc_table['mag'] = adjusted_lc_table['mag'] - peak_mag_difference\n",
    "    \n",
    "    return adjusted_lc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error(survey):\n",
    "    \n",
    "    #Calculate the error of the magnitude at each point from the magnitude and fiveSigmaDepth stored in survey\n",
    "    \n",
    "    snr = 5.*10.**(-0.4*(survey['magnitude'] - survey['fiveSigmaDepth']))\n",
    "    lc_err = 2.5/(np.log(10)*snr)\n",
    "    survey['error'] = lc_err\n",
    "    \n",
    "    return survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_light_curve(opsim_fmatch2, f, ra, dec, day, mag):\n",
    "    \n",
    "    #Plot the resampled light curve (day vs. magnitude) with error for each filter\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.errorbar(opsim_fmatch2['day'], opsim_fmatch2['magnitude'], opsim_fmatch2['error'], fmt = 'o', color=colors[f])\n",
    "    ax.set_ylim(20,15)\n",
    "    ax.set_xlim(0,365)\n",
    "    ax.set_xlabel('Days')\n",
    "    ax.set_ylabel('Magnitude')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles = [h[0] for h in handles]\n",
    "    ax.legend(handles, [f for f in filterNames], fontsize='smaller', numpoints=1)\n",
    "    ax.set_title('Resampled Light Curve for ra = %r and dec = %r and peakday = %d and peakmag = %d ' %(ra, dec, day, mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_original(lc_table, times):\n",
    "    lc_original = {}\n",
    "    #for each filter plot the corresponding light curve created in Make_LightCurve\n",
    "    for f in filterNames:\n",
    "        fMatch = np.where(lc_table['filter'] == f)\n",
    "        lc_original[f] = np.interp(times, lc_table['day'][fMatch], lc_table['mag'][fMatch])\n",
    "    lightcurve2 = Table(lc_original)\n",
    "    lightcurve2['day'] = times\n",
    "    lightcurve2 = lightcurve2['day', 'g', 'r', 'i', 'z']\n",
    "    return lightcurve2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_lightcurve_to_table(lightcurve2):\n",
    "    \n",
    "    opsim2 = Table()\n",
    "    opsim2.add_column(Column(name='day'))\n",
    "    opsim2.add_column(Column(name='mangitude'))\n",
    "    opsim2.add_column(Column(name='filter'))\n",
    "    opsim2 = Table(names=('day', 'magnitude', 'filter'), dtype=('float', 'float', 'string'))\n",
    "    for day in lightcurve2['day']:\n",
    "        for f in filterNames:\n",
    "            row = np.where(lightcurve2['day'] == day)\n",
    "            opsim2.add_row([day, lightcurve2[f][row][0], f])            \n",
    "    return opsim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func2(x, a, b, c, d, e):\n",
    "    return a*x**4 + b*x**3 + c*x**2 + d*x + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_curve2(2, 3, f, adjusted_lc_table, ra, dec, peakday, peakmag):\n",
    "    curve = np.copy(2)\n",
    "    curve = Table(curve)\n",
    "    fMatch = np.where(adjusted_lc_table['filter'] == f)\n",
    "    curve = curve[curve['day'] <= adjusted_lc_table['day'][fMatch].max()]\n",
    "\n",
    "    survey2 = np.copy(3)\n",
    "    survey2 = Table(survey2)\n",
    "    survey2 = survey2[survey2['day'] <= adjusted_lc_table['day'][fMatch].max()]\n",
    "\n",
    "    xdata = np.arange(0, curve['day'].max(), 1)\n",
    "    popt, pcov = optimize.curve_fit(func2, curve['day'], curve['magnitude'])\n",
    "    plt.plot(xdata, func2(xdata, *popt), 'orange' , label='fit')\n",
    "    plt.errorbar(curve['day'], curve['magnitude'], \n",
    "               yerr = curve['error'], fmt = 'o', color=colors[f], label=f)\n",
    "    plt.plot(survey2['day'], survey2['magnitude'], color=colors[f], label=f)\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('magnitude')\n",
    "    plt.ylim(20,15)\n",
    "    plt.legend(numpoints = 1)\n",
    "    plt.title('Lightcurve at ra = %r and dec = %r, peakday = %r and peakmag = %r' %(ra, dec, peakday, peakmag))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampled_peak_magnitude(opsim_fmatch2, f, adjusted_lc_table, ra, dec):\n",
    "  \n",
    "    fMatch = np.where(adjusted_lc_table['filter'] == f)\n",
    "\n",
    "    survey = np.copy(opsim_fmatch2)\n",
    "    survey = Table(survey)\n",
    "    survey = survey[survey['day'] <= adjusted_lc_table['day'][fMatch].max()]\n",
    "\n",
    "    xdata = np.arange(0, survey['day'].max(), 2)\n",
    "    popt, pcov = optimize.curve_fit(func2, survey['day'], survey['magnitude'])\n",
    "\n",
    "    peak_magnitude_difference = abs(adjusted_lc_table['mag'].min() - func2(xdata, *popt).min())\n",
    "    \n",
    "    print('ra = %r, dec = %r, filter = %s, peak magnitude difference = %r' %(ra, dec, f, peak_magnitude_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resampled_peak_day(opsim_fmatch2, f, adjusted_lc_table, ra, dec):\n",
    "\n",
    "    fMatch = np.where(adjusted_lc_table['filter'] == f)\n",
    "\n",
    "    survey = np.copy(opsim_fmatch2)\n",
    "    survey = Table(survey)\n",
    "    survey = survey[survey['day'] <= adjusted_lc_table['day'][fMatch].max()]\n",
    "\n",
    "    xdata = np.arange(0, survey['day'].max() + 10, 1)\n",
    "    popt, pcov = optimize.curve_fit(func2, survey['day'], survey['magnitude'])\n",
    "\n",
    "    actual_peak_day = adjusted_lc_table['day'][adjusted_lc_table['mag'].argmin()]\n",
    "    fitted_peak_day = func2(xdata, *popt).argmin()\n",
    "    peak_day_difference = abs(actual_peak_day - fitted_peak_day)\n",
    "    print('ra = %r, dec = %r, filter = %s, peak magnitude difference = %r' %(ra, dec, f, peak_day_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_curve = ReadCurve(jsonLC)\n",
    "lc_table = read_curve.read_lightcurve(jsonLC)\n",
    "peakTable = peak_brightness(lc_table)\n",
    "survey = createdict_for_mjd_filter_depth(bundle)\n",
    "bdict = {}\n",
    "for coord in range(len(bundle.metricValues)):\n",
    "    enough = 0.\n",
    "    not_enough = 0.\n",
    "    opsim = list(survey)\n",
    "    opsim = opsim[coord]\n",
    "    opsim = opsim['fieldRA', 'fieldDec', 'day', 'filter', 'fiveSigmaDepth']\n",
    "    opsim = opsim[opsim['filter'] != 'u']\n",
    "    opsim = opsim[opsim['filter'] != 'y']\n",
    "    \n",
    "    ra = np.degrees(round(opsim['fieldRA'][0], 4))\n",
    "    dec = np.degrees(round(opsim['fieldDec'][0], 4))\n",
    "    \n",
    "    opsim['day'] = (opsim['day'] - opsim['day'].min())\n",
    "    opsim.sort('day')\n",
    "    \n",
    "    for peakday in location_of_peak:\n",
    "        for peakmag in height_of_peak:\n",
    "            adjusted_lc_table = adjust_peak(lc_table, peakTable, peakday, peakmag)\n",
    "            new_opsim = opsim.copy()\n",
    "            new_opsim = new_opsim[new_opsim['day']< adjusted_lc_table['day'].max()]\n",
    "            new_opsim = new_opsim[new_opsim['day']> adjusted_lc_table['day'].min()]\n",
    "            lightcurve = interpolate_light_curve(adjusted_lc_table, new_opsim)\n",
    "            opsim1 = resample_light_curve(lightcurve, new_opsim)\n",
    "            opsim1 = calculate_error(opsim1)\n",
    "            \n",
    "            times = np.arange(new_opsim['day'].min(), new_opsim['day'].max(), 1)\n",
    "            lightcurve2 = interpolate_original(adjusted_lc_table, times)\n",
    "            opsim2 = change_lightcurve_to_table(lightcurve2)\n",
    "            \n",
    "            final_opsim = opsim1.copy()\n",
    "            final_opsim = final_opsim[final_opsim['day'] <= 30]\n",
    "            for f in filterNames:\n",
    "                fMatch = np.where(final_opsim['filter'] == f)\n",
    "                fMatch2 = np.where(opsim1['filter'] == f)\n",
    "                fMatch3 = np.where(opsim2['filter'] == f)\n",
    "                opsim_fmatch = final_opsim[fMatch]\n",
    "                opsim_fmatch2 = opsim1[fMatch2]\n",
    "                opsim_fmatch3 = opsim2[fMatch3]\n",
    "                if len(opsim_fmatch) >= 5:\n",
    "                    #print('enough points for filter = %s, ra = %r, dec = %r' %(f, ra, dec))\n",
    "                    #plot_light_curve(opsim_fmatch2, f, ra, dec, peakday, peakmag)\n",
    "                    create_curve2(opsim_fmatch, opsim_fmatch3, f, adjusted_lc_table, ra, dec, peakday, peakmag)\n",
    "                    #resampled_peak_magnitude(opsim_fmatch2, f, adjusted_lc_table, ra, dec)\n",
    "                    #resampled_peak_day(opsim_fmatch2, f, adjusted_lc_table, ra, dec)\n",
    "                    enough += 1\n",
    "                else:\n",
    "                    not_enough += 1\n",
    "    #percent_with_atleast_4 = enough/(enough + not_enough)*100\n",
    "    #bdict[ra,dec] = percent_with_atleast_4\n",
    "#print bdict\n",
    "#print('enough = %d' %(enough))\n",
    "#print('not enough = %d' %(not_enough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
